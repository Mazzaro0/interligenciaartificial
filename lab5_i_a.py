# -*- coding: utf-8 -*-
"""LAB5-I.A

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11IQIR9Pm6cOcLqJtUoslf5BygQxct6EN
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error

# Definição das funções para os testes 2 a 5
def function_2(x):
    return np.cos(x)

def function_3(x):
    return np.exp(-0.1 * x**2)

def function_4(x):
    return np.sin(x) * np.cos(x)

def function_5(x):
    return np.log(np.abs(x) + 1)

# Lista de funções e nomes
tests = {
    "Teste 2 (cos(x))": function_2,
    "Teste 3 (exp(-0.1*x^2))": function_3,
    "Teste 4 (sin(x) * cos(x))": function_4,
    "Teste 5 (log(|x| + 1))": function_5
}

# Configuração das redes neurais (3 arquiteturas diferentes)
architectures = [
    (10,),  # 1 camada oculta com 10 neurônios
    (20, 10),  # 2 camadas ocultas com 20 e 10 neurônios
    (50, 20, 10)  # 3 camadas ocultas com 50, 20 e 10 neurônios
]

# Gerar os resultados para cada função e arquitetura
results = {}

for test_name, function in tests.items():
    X = np.linspace(-2 * np.pi, 2 * np.pi, 100).reshape(-1, 1)
    y = function(X).ravel()

    results[test_name] = {}

    for arch in architectures:
        errors = []
        for i in range(10):  # Executar 10 vezes
            model = MLPRegressor(hidden_layer_sizes=arch, max_iter=1000, random_state=i)
            model.fit(X, y)
            y_pred = model.predict(X)
            error = mean_squared_error(y, y_pred)
            errors.append(error)

        # Armazenar resultados
        results[test_name][arch] = {
            "mean_error": np.mean(errors),
            "std_error": np.std(errors),
            "y_pred": model.predict(X)  # Melhor modelo da última execução
        }

# Gerar gráficos
for test_name, test_results in results.items():
    plt.figure(figsize=(10, 5))
    plt.scatter(X, tests[test_name](X).ravel(), label="Dados reais", color="blue", alpha=0.5)

    for arch in architectures:
        plt.plot(X, test_results[arch]["y_pred"], label=f"Arquitetura {arch}")

    plt.legend()
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.title(f"Aproximação de função - {test_name}")
    plt.show()

# Exibir erros médios e desvios padrão
for test_name, test_results in results.items():
    print(f"Resultados para {test_name}:")
    for arch, res in test_results.items():
        print(f"  Arquitetura {arch}: Erro médio = {res['mean_error']:.5f}, Desvio padrão = {res['std_error']:.5f}")
    print()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error

# Definição das funções para os testes 2 a 5
def function_2(x):
    return np.cos(x)

def function_3(x):
    return np.exp(-0.1 * x**2)

def function_4(x):
    return np.sin(x) * np.cos(x)

def function_5(x):
    return np.log(np.abs(x) + 1)

# Lista de funções e nomes
tests = {
    "Teste 2 (cos(x))": function_2,
    "Teste 3 (exp(-0.1*x^2))": function_3,
    "Teste 4 (sin(x) * cos(x))": function_4,
    "Teste 5 (log(|x| + 1))": function_5
}

# Configuração das redes neurais (3 arquiteturas diferentes)
architectures = [
    (10,),  # 1 camada oculta com 10 neurônios
    (20, 10),  # 2 camadas ocultas com 20 e 10 neurônios
    (50, 20, 10)  # 3 camadas ocultas com 50, 20 e 10 neurônios
]

# Gerar os resultados para cada função e arquitetura
results = {}

for test_name, function in tests.items():
    X = np.linspace(-2 * np.pi, 2 * np.pi, 100).reshape(-1, 1)
    y = function(X).ravel()

    results[test_name] = {}

    for arch in architectures:
        errors = []
        for i in range(10):  # Executar 10 vezes
            model = MLPRegressor(hidden_layer_sizes=arch, max_iter=1000, random_state=i)
            model.fit(X, y)
            y_pred = model.predict(X)
            error = mean_squared_error(y, y_pred)
            errors.append(error)

        # Armazenar resultados
        results[test_name][arch] = {
            "mean_error": np.mean(errors),
            "std_error": np.std(errors),
            "y_pred": model.predict(X)  # Melhor modelo da última execução
        }

# Gerar gráficos
for test_name, test_results in results.items():
    plt.figure(figsize=(10, 5))
    plt.scatter(X, tests[test_name](X).ravel(), label="Dados reais", color="blue", alpha=0.5)

    for arch in architectures:
        plt.plot(X, test_results[arch]["y_pred"], label=f"Arquitetura {arch}")

    plt.legend()
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.title(f"Aproximação de função - {test_name}")
    plt.show()

# Exibir erros médios e desvios padrão
for test_name, test_results in results.items():
    print(f"Resultados para {test_name}:")
    for arch, res in test_results.items():
        print(f"  Arquitetura {arch}: Erro médio = {res['mean_error']:.5f}, Desvio padrão = {res['std_error']:.5f}")
    print()